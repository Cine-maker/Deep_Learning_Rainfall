{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  Bãi Cháy  Cà Mau  Đà Lạt  Đà Nẵng  Hà Nội     Huế  Lai Châu  \\\n",
      "0             0       5.0    4.00   10.74     33.0     9.0    73.0      73.0   \n",
      "1             1      21.0   28.41   14.00     64.0    24.0    31.0      53.0   \n",
      "2             2      12.0    1.00  120.00      4.0    11.0    22.0      78.0   \n",
      "3             3      17.0    4.00  102.00    113.0    59.0    56.0     114.0   \n",
      "4             4     413.0  274.00  123.00     39.0   214.0   242.0     341.0   \n",
      "..          ...       ...     ...     ...      ...     ...     ...       ...   \n",
      "247         247     708.4  228.30  280.60    187.0   486.3   157.5     257.9   \n",
      "248         248     461.2  409.20  293.70    419.4   242.0   448.8     166.1   \n",
      "249         249     210.2  352.70  159.50   1219.6    84.4  1366.5      72.9   \n",
      "250         250      34.9  313.30   99.10    156.6     7.8   226.4     111.0   \n",
      "251         251       1.5   71.90   37.90    349.7    13.7   786.6      72.6   \n",
      "\n",
      "     Nam Định  Nha Trang  Pleiku  Quy Nhơn  Sơn La  Tuyên Quang    Vinh  \\\n",
      "0         4.0       1.00    2.10     15.00    61.0         31.0    24.0   \n",
      "1         8.0      14.39    5.97     25.78    22.0         25.0    32.0   \n",
      "2        19.0      37.48    1.00      4.00    55.0         61.0    84.0   \n",
      "3        46.0      18.00   19.00     27.00    65.0         61.0    46.0   \n",
      "4       366.0      53.00  270.00     50.00   328.0        241.0   263.0   \n",
      "..        ...        ...     ...       ...     ...          ...     ...   \n",
      "247     515.0     154.50  342.30     64.80   333.6        447.8   166.3   \n",
      "248     653.0      81.90  598.50    509.70   167.1        301.1  1166.7   \n",
      "249     285.2     436.90   89.30    577.40     3.8         35.4   352.0   \n",
      "250      87.0     333.90   33.80    421.00    51.1         11.2   718.6   \n",
      "251      10.7     412.30   16.20    328.20    27.4         12.9    47.2   \n",
      "\n",
      "     Vũng Tàu  \n",
      "0       10.84  \n",
      "1        9.03  \n",
      "2       10.83  \n",
      "3        5.00  \n",
      "4      126.00  \n",
      "..        ...  \n",
      "247    225.00  \n",
      "248    265.10  \n",
      "249    363.10  \n",
      "250     86.40  \n",
      "251     39.60  \n",
      "\n",
      "[252 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "rainfall_path = 'rainfall.xlsx'  # Replace with your CSV file path\n",
    "num_features = 1  # Assuming each time step has one feature (you may need to adjust this)\n",
    "embedding_size = 64  # Adjust the embedding size as needed\n",
    "\n",
    "# Load CSV data\n",
    "data = pd.read_excel(rainfall_path)\n",
    "print(data)\n",
    "# Assuming the CSV file has columns for each time series and rows for each time step\n",
    "# You may need to adjust this depending on the structure of your CSV file\n",
    "num_time_series = len(data.columns)\n",
    "num_time_steps = len(data)\n",
    "\n",
    "# Convert data to PyTorch tensor\n",
    "data_tensor = torch.tensor(data.values, dtype=torch.float32)\n",
    "\n",
    "# Reshape the data tensor to match the expected input dimensions of the EmbeddingModule\n",
    "data_tensor = data_tensor.view(1, num_time_steps, 1, num_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded data shape: torch.Size([1, 16, 252, 64])\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingModule(nn.Module):\n",
    "    def __init__(self, num_features, embedding_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input into dimensions (batch_size, num_features, num_time_series, num_time_steps)\n",
    "        x = x.permute(0, 3, 1, 2)   \n",
    "\n",
    "        # Apply feature-wise linear embedding\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x   \n",
    "embedding_module = EmbeddingModule(num_features, embedding_size)\n",
    "\n",
    "# Apply the embedding module to the data\n",
    "embedding_result = embedding_module(data_tensor)\n",
    "print(\"Embedded data shape:\", embedding_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingModule(nn.Module):\n",
    "    def __init__(self, num_features, embedding_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Reshape input into dimensions (batch_size, num_features, num_time_series, num_time_steps)\n",
    "        x = x.permute(0, 3, 1, 2)   \n",
    "\n",
    "        # Apply feature-wise linear embedding\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x   \n",
    "\n",
    "class LTCN(nn.Module):\n",
    "    def __init__(self, embedding_size, num_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(embedding_size, num_channels, kernel_size=(1,5))\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=(1, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  \n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        \n",
    "        # Keep only last timestep \n",
    "        x = x[..., -1:]  \n",
    "        \n",
    "        return x\n",
    "\n",
    "class GLFormer(nn.Module):\n",
    "    def __init__(self, embedding_size): \n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(embedding_size, nhead=4)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(1, 0, 2, 3)    \n",
    "        x = self.transformer(x) \n",
    "        return x.permute(1, 0, 2, 3)\n",
    "    \n",
    "class LightCTS(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding = EmbeddingModule(num_features=2, embedding_size=64)   \n",
    "        self.ltcn = LTCN(embedding_size=64, num_channels=32)\n",
    "        self.glformer = GLFormer(embedding_size=64)\n",
    "        \n",
    "        self.linear = nn.Linear(64, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) \n",
    "        x = self.ltcn(x) \n",
    "        x = self.glformer(x)\n",
    "        \n",
    "        # Flatten across time series dimension\n",
    "        x = torch.flatten(x, start_dim=1)  \n",
    "        return self.linear(x)   \n",
    "\n",
    "model = LightCTS() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
